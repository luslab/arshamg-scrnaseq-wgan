{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANN - CHECK SPELLING\n",
    "\n",
    "## Setup\n",
    "\n",
    "Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "\n",
    "train_feature_path = data_path + '/tpm_combined.csv'\n",
    "train_gene_name_path = data_path + '/tpm_combined_rows.csv'\n",
    "train_cell_name_path = data_path + '/tpm_combined_cols.csv'\n",
    "\n",
    "test_feature_path = data_path + '/tpm_combined_test.csv'\n",
    "test_gene_name_path = data_path + '/tpm_combined_rows_test.csv'\n",
    "test_cell_name_path = data_path + '/tpm_combined_cols_test.csv'\n",
    "\n",
    "train_nonorm_path = data_path + '/tpm_combined_train_nonorm.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load datasets into frames and check all the shapes match up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6807, 1)\n",
      "(1798, 1)\n",
      "(6807, 1798)\n"
     ]
    }
   ],
   "source": [
    "df_gene_names = pd.read_csv(train_gene_name_path, header=None)\n",
    "df_cell_names = pd.read_csv(train_cell_name_path, header=None)\n",
    "df_training_data = pd.read_csv(train_feature_path, header=None)\n",
    "\n",
    "df_gene_names.columns = ['gene_name']\n",
    "\n",
    "print(df_gene_names.shape)\n",
    "print(df_cell_names.shape)\n",
    "print(df_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.828987016884007\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df_training_data_nonorm = pd.read_csv(train_nonorm_path)\n",
    "df_training_data_nonorm = df_training_data_nonorm.drop('gene_name', axis=1)\n",
    "\n",
    "nonorm_max = df_training_data_nonorm.max().max()\n",
    "nonorm_min = df_training_data_nonorm.min().min()\n",
    "del df_training_data_nonorm\n",
    "\n",
    "print(nonorm_max)\n",
    "print(nonorm_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6807, 1)\n",
      "(500, 1)\n",
      "(6807, 500)\n"
     ]
    }
   ],
   "source": [
    "df_gene_names_test = pd.read_csv(test_gene_name_path, header=None)\n",
    "df_cell_names_test = pd.read_csv(test_cell_name_path, header=None)\n",
    "df_test_data = pd.read_csv(test_feature_path, header=None)\n",
    "\n",
    "print(df_gene_names_test.shape)\n",
    "print(df_cell_names_test.shape)\n",
    "print(df_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of genes in the input dataset determines the generator output as well as the dicriminator inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6807, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_genes = df_gene_names.shape[0]\n",
    "df_gene_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593519</td>\n",
       "      <td>0.724994</td>\n",
       "      <td>0.259323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397072</td>\n",
       "      <td>0.679657</td>\n",
       "      <td>0.541898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567361</td>\n",
       "      <td>0.442711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529515</td>\n",
       "      <td>0.730789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291240</td>\n",
       "      <td>0.356175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252119</td>\n",
       "      <td>0.065884</td>\n",
       "      <td>0.734733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378425</td>\n",
       "      <td>0.347020</td>\n",
       "      <td>0.812647</td>\n",
       "      <td>0.487845</td>\n",
       "      <td>0.297422</td>\n",
       "      <td>0.516562</td>\n",
       "      <td>0.304545</td>\n",
       "      <td>0.488694</td>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.805992</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.351573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605841</td>\n",
       "      <td>0.802402</td>\n",
       "      <td>0.681187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632745</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>0.112515</td>\n",
       "      <td>0.506412</td>\n",
       "      <td>0.657094</td>\n",
       "      <td>0.628180</td>\n",
       "      <td>0.554082</td>\n",
       "      <td>0.738973</td>\n",
       "      <td>0.764555</td>\n",
       "      <td>0.726907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608894</td>\n",
       "      <td>0.586006</td>\n",
       "      <td>0.696437</td>\n",
       "      <td>0.427761</td>\n",
       "      <td>0.681078</td>\n",
       "      <td>0.672670</td>\n",
       "      <td>0.536335</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.675192</td>\n",
       "      <td>0.527422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.681206</td>\n",
       "      <td>0.236664</td>\n",
       "      <td>0.428852</td>\n",
       "      <td>0.420482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267296</td>\n",
       "      <td>0.625472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423746</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>0.395655</td>\n",
       "      <td>0.749851</td>\n",
       "      <td>0.385655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483893</td>\n",
       "      <td>0.697602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0.830038</td>\n",
       "      <td>0.741090</td>\n",
       "      <td>0.606057</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384173</td>\n",
       "      <td>0.265556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444041</td>\n",
       "      <td>0.748770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557804</td>\n",
       "      <td>0.859781</td>\n",
       "      <td>0.868549</td>\n",
       "      <td>0.625063</td>\n",
       "      <td>0.571023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>0.430313</td>\n",
       "      <td>0.090124</td>\n",
       "      <td>0.605318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520718</td>\n",
       "      <td>0.162545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680744</td>\n",
       "      <td>0.128438</td>\n",
       "      <td>0.432505</td>\n",
       "      <td>0.656399</td>\n",
       "      <td>0.424025</td>\n",
       "      <td>0.275454</td>\n",
       "      <td>0.148875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649158</td>\n",
       "      <td>0.808326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491346</td>\n",
       "      <td>0.146496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>0.588273</td>\n",
       "      <td>0.442550</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294135</td>\n",
       "      <td>0.808406</td>\n",
       "      <td>0.561273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639111</td>\n",
       "      <td>0.556518</td>\n",
       "      <td>0.384235</td>\n",
       "      <td>0.255971</td>\n",
       "      <td>0.819070</td>\n",
       "      <td>0.628633</td>\n",
       "      <td>0.633401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 1798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.593519  0.724994  0.259323  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.529515  0.730789  0.000000  0.291240  0.356175  0.000000  0.000000   \n",
       "2     0.805992  0.015907  0.351573  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.632745  0.442018  0.112515  0.506412  0.657094  0.628180  0.554082   \n",
       "4     0.681206  0.236664  0.428852  0.420482  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6802  0.395655  0.749851  0.385655  0.000000  0.483893  0.697602  0.000000   \n",
       "6803  0.000000  0.384173  0.265556  0.000000  0.000000  0.000000  0.000000   \n",
       "6804  0.430313  0.090124  0.605318  0.000000  0.000000  0.000000  0.000000   \n",
       "6805  0.000000  0.000000  0.000000  0.621492  0.000000  0.649158  0.808326   \n",
       "6806  0.588273  0.442550  0.739593  0.000000  0.000000  0.459884  0.000000   \n",
       "\n",
       "          7         8         9     ...      1788      1789      1790  \\\n",
       "0     0.000000  0.000000  0.000000  ...  0.000000  0.397072  0.679657   \n",
       "1     0.252119  0.065884  0.734733  ...  0.378425  0.347020  0.812647   \n",
       "2     0.000000  0.000000  0.551268  ...  0.000000  0.661508  0.000000   \n",
       "3     0.738973  0.764555  0.726907  ...  0.608894  0.586006  0.696437   \n",
       "4     0.000000  0.267296  0.625472  ...  0.423746  0.111500  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6802  0.000000  0.000000  0.747306  ...  0.000000  0.455800  0.000000   \n",
       "6803  0.000000  0.444041  0.748770  ...  0.000000  0.000000  0.000000   \n",
       "6804  0.000000  0.520718  0.162545  ...  0.000000  0.680744  0.128438   \n",
       "6805  0.000000  0.589434  0.000000  ...  0.625170  0.000000  0.000000   \n",
       "6806  0.294135  0.808406  0.561273  ...  0.000000  0.639111  0.556518   \n",
       "\n",
       "          1791      1792      1793      1794      1795      1796      1797  \n",
       "0     0.541898  0.000000  0.000000  0.567361  0.442711  0.000000  0.000000  \n",
       "1     0.487845  0.297422  0.516562  0.304545  0.488694  0.266055  0.000000  \n",
       "2     0.605841  0.802402  0.681187  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.427761  0.681078  0.672670  0.536335  0.451429  0.675192  0.527422  \n",
       "4     0.622586  0.000000  0.611686  0.000000  0.502279  0.000000  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6802  0.420597  0.000000  0.407697  0.830038  0.741090  0.606057  0.000000  \n",
       "6803  0.000000  0.000000  0.557804  0.859781  0.868549  0.625063  0.571023  \n",
       "6804  0.432505  0.656399  0.424025  0.275454  0.148875  0.000000  0.000000  \n",
       "6805  0.000000  0.000000  0.491346  0.146496  0.000000  0.000000  0.000000  \n",
       "6806  0.384235  0.255971  0.819070  0.628633  0.633401  0.000000  0.518773  \n",
       "\n",
       "[6807 rows x 1798 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model variables - COMMENT ON EACH ONE TO DESCRIBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "LATENT_VARIABLE_SIZE = 100\n",
    "GEN_L1_DENSE_SIZE = 600\n",
    "GEN_L2_DENSE_SIZE = 600\n",
    "GEN_L3_DENSE_SIZE = num_genes\n",
    "\n",
    "DIS_INPUT_SIZE = num_genes\n",
    "DIS_L1_DENSE_SIZE = 200\n",
    "DIS_L2_DENSE_SIZE = 200\n",
    "\n",
    "NOISE_STDEV = 0.1\n",
    "POISSON_LAM = 1\n",
    "\n",
    "# Training params\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "TRAIN_BUFFER_SIZE = 10000\n",
    "TEST_BATCH_SIZE = 500\n",
    "TEST_BUFFER_SIZE = 500\n",
    "GEN_BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "\n",
    "EX_GEN_BATCH_SIZE = 500\n",
    "\n",
    "#LEARNING_RATE = 0.001\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test datasets\n",
    "\n",
    "Create tensors from training data - Convert to Int32 for better work on GPU with batch and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (None, 6807), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(df_training_data.T.values.astype('float32')).shuffle(TRAIN_BUFFER_SIZE).batch(TRAIN_BATCH_SIZE)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (None, 6807), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(df_test_data.T.values.astype('float32')).shuffle(TEST_BUFFER_SIZE).batch(TEST_BATCH_SIZE)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GANN model\n",
    "\n",
    "Define function for contructing the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #L1\n",
    "    model.add(layers.Dense(GEN_L1_DENSE_SIZE, use_bias=False, input_shape=(LATENT_VARIABLE_SIZE,)))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #assert model.output_shape == (None, GEN_L1_DENSE_SIZE, 1)  # Note: None is the batch size\n",
    "    \n",
    "    #L2\n",
    "    model.add(layers.Dense(GEN_L2_DENSE_SIZE, use_bias=False))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #assert model.output_shape == (None, GEN_L2_DENSE_SIZE, 1)\n",
    "    \n",
    "    #L3\n",
    "    model.add(layers.Dense(GEN_L3_DENSE_SIZE, use_bias=False))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #assert model.output_shape == (None, GEN_L3_DENSE_SIZE, 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for constructing discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #L1\n",
    "    model.add(layers.Dense(DIS_L1_DENSE_SIZE, use_bias=False, input_shape=(DIS_INPUT_SIZE,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    #L2\n",
    "    model.add(layers.Dense(DIS_L2_DENSE_SIZE, use_bias=False))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    #L3\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the noise generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size):\n",
    "    # Create some random noise for the generator\n",
    "    n_noise = tf.random.normal([batch_size, LATENT_VARIABLE_SIZE], mean=0.0, stddev=NOISE_STDEV)\n",
    "    p_noise = tf.random.poisson([batch_size, LATENT_VARIABLE_SIZE], lam=POISSON_LAM)\n",
    "    noise = tf.abs(n_noise + p_noise)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "    \n",
    "    #total_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)\n",
    "    #return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    #total_loss = -tf.reduce_mean(fake_output)\n",
    "    #return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_from_gen(profile, label):\n",
    "    # Create formatted dataframe from generator result\n",
    "    df_gen_prof = pd.DataFrame(generated_profile.numpy()).T\n",
    "    df_gen_prof = df_gene_names.join(df_gen_prof, lsuffix='', rsuffix='', how='inner')\n",
    "    df_gen_prof.index = df_gen_prof.gene_name\n",
    "    df_gen_prof = df_gen_prof.drop('gene_name', axis=1)\n",
    "    df_gen_prof = df_gen_prof.add_prefix(label)\n",
    "\n",
    "    # Get limits\n",
    "    gen_min = df_gen_prof.min().min()\n",
    "    gen_max = df_gen_prof.max().max()\n",
    "\n",
    "    # Scale everything up to 0\n",
    "    df_gen_prof = df_gen_prof + (gen_min*-1)\n",
    "    gen_max = df_gen_prof.max().max()\n",
    "    gen_min = df_gen_prof.min().min()\n",
    "\n",
    "    # Rescale to between real world min maxes\n",
    "    df_gen_prof = df_gen_prof / gen_max\n",
    "    df_gen_prof = df_gen_prof * nonorm_max\n",
    "    \n",
    "    return df_gen_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is a batch of real cell profiles from the training set\n",
    "# @tf.function\n",
    "def train_step(cell_profiles):\n",
    "    noise = gen_noise(GEN_BATCH_SIZE)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_profiles = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(cell_profiles, training=True)\n",
    "        fake_output = discriminator(generated_profiles, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        met_gen_loss(gen_loss)\n",
    "        met_disc_loss(disc_loss)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GANN model\n",
    "\n",
    "Create generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator()\n",
    "discriminator = create_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from test data to check network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gencell_ep0_0</th>\n",
       "      <th>gencell_ep0_1</th>\n",
       "      <th>gencell_ep0_2</th>\n",
       "      <th>gencell_ep0_3</th>\n",
       "      <th>gencell_ep0_4</th>\n",
       "      <th>gencell_ep0_5</th>\n",
       "      <th>gencell_ep0_6</th>\n",
       "      <th>gencell_ep0_7</th>\n",
       "      <th>gencell_ep0_8</th>\n",
       "      <th>gencell_ep0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gencell_ep0_490</th>\n",
       "      <th>gencell_ep0_491</th>\n",
       "      <th>gencell_ep0_492</th>\n",
       "      <th>gencell_ep0_493</th>\n",
       "      <th>gencell_ep0_494</th>\n",
       "      <th>gencell_ep0_495</th>\n",
       "      <th>gencell_ep0_496</th>\n",
       "      <th>gencell_ep0_497</th>\n",
       "      <th>gencell_ep0_498</th>\n",
       "      <th>gencell_ep0_499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rfc3</th>\n",
       "      <td>8.945637</td>\n",
       "      <td>5.733241</td>\n",
       "      <td>3.860522</td>\n",
       "      <td>5.619954</td>\n",
       "      <td>5.586335</td>\n",
       "      <td>6.970235</td>\n",
       "      <td>4.338315</td>\n",
       "      <td>4.549016</td>\n",
       "      <td>5.009731</td>\n",
       "      <td>4.163322</td>\n",
       "      <td>...</td>\n",
       "      <td>5.424246</td>\n",
       "      <td>4.402611</td>\n",
       "      <td>4.928729</td>\n",
       "      <td>4.162288</td>\n",
       "      <td>3.108255</td>\n",
       "      <td>3.963334</td>\n",
       "      <td>4.221949</td>\n",
       "      <td>5.123520</td>\n",
       "      <td>5.077371</td>\n",
       "      <td>4.183359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cd47</th>\n",
       "      <td>3.738709</td>\n",
       "      <td>6.256884</td>\n",
       "      <td>4.448080</td>\n",
       "      <td>4.054791</td>\n",
       "      <td>3.151270</td>\n",
       "      <td>5.373478</td>\n",
       "      <td>4.040785</td>\n",
       "      <td>3.867641</td>\n",
       "      <td>3.853901</td>\n",
       "      <td>3.849575</td>\n",
       "      <td>...</td>\n",
       "      <td>4.048962</td>\n",
       "      <td>3.853764</td>\n",
       "      <td>3.765724</td>\n",
       "      <td>4.609506</td>\n",
       "      <td>3.302379</td>\n",
       "      <td>3.876153</td>\n",
       "      <td>4.352907</td>\n",
       "      <td>4.469342</td>\n",
       "      <td>3.901982</td>\n",
       "      <td>4.072795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elmo2</th>\n",
       "      <td>5.200176</td>\n",
       "      <td>5.034015</td>\n",
       "      <td>4.367820</td>\n",
       "      <td>4.389033</td>\n",
       "      <td>3.275808</td>\n",
       "      <td>4.553952</td>\n",
       "      <td>4.151926</td>\n",
       "      <td>4.272325</td>\n",
       "      <td>5.511501</td>\n",
       "      <td>5.136298</td>\n",
       "      <td>...</td>\n",
       "      <td>6.041917</td>\n",
       "      <td>7.925032</td>\n",
       "      <td>4.330449</td>\n",
       "      <td>5.032185</td>\n",
       "      <td>6.416893</td>\n",
       "      <td>3.790214</td>\n",
       "      <td>4.398872</td>\n",
       "      <td>4.268808</td>\n",
       "      <td>6.591664</td>\n",
       "      <td>6.079050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crip2</th>\n",
       "      <td>6.406047</td>\n",
       "      <td>6.777477</td>\n",
       "      <td>4.845940</td>\n",
       "      <td>5.980703</td>\n",
       "      <td>6.169468</td>\n",
       "      <td>3.798367</td>\n",
       "      <td>5.310357</td>\n",
       "      <td>5.590196</td>\n",
       "      <td>5.810795</td>\n",
       "      <td>4.467186</td>\n",
       "      <td>...</td>\n",
       "      <td>6.990990</td>\n",
       "      <td>5.949615</td>\n",
       "      <td>4.702023</td>\n",
       "      <td>6.335579</td>\n",
       "      <td>6.546120</td>\n",
       "      <td>4.798983</td>\n",
       "      <td>6.166876</td>\n",
       "      <td>5.177269</td>\n",
       "      <td>5.966042</td>\n",
       "      <td>4.368247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pprc1</th>\n",
       "      <td>3.406488</td>\n",
       "      <td>4.168306</td>\n",
       "      <td>3.645792</td>\n",
       "      <td>4.300521</td>\n",
       "      <td>4.956060</td>\n",
       "      <td>4.561098</td>\n",
       "      <td>4.906742</td>\n",
       "      <td>3.943385</td>\n",
       "      <td>5.413904</td>\n",
       "      <td>3.865657</td>\n",
       "      <td>...</td>\n",
       "      <td>4.532197</td>\n",
       "      <td>5.760712</td>\n",
       "      <td>3.690476</td>\n",
       "      <td>4.809052</td>\n",
       "      <td>5.970742</td>\n",
       "      <td>6.596510</td>\n",
       "      <td>4.736276</td>\n",
       "      <td>4.186600</td>\n",
       "      <td>4.369345</td>\n",
       "      <td>5.713038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hprt</th>\n",
       "      <td>3.915553</td>\n",
       "      <td>3.186345</td>\n",
       "      <td>3.832254</td>\n",
       "      <td>2.772286</td>\n",
       "      <td>2.920236</td>\n",
       "      <td>3.778947</td>\n",
       "      <td>3.616331</td>\n",
       "      <td>3.301115</td>\n",
       "      <td>3.704352</td>\n",
       "      <td>4.052122</td>\n",
       "      <td>...</td>\n",
       "      <td>4.769273</td>\n",
       "      <td>4.114681</td>\n",
       "      <td>3.481516</td>\n",
       "      <td>4.099298</td>\n",
       "      <td>4.000013</td>\n",
       "      <td>3.558737</td>\n",
       "      <td>3.259285</td>\n",
       "      <td>3.562539</td>\n",
       "      <td>3.231498</td>\n",
       "      <td>2.215208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atraid</th>\n",
       "      <td>5.856579</td>\n",
       "      <td>8.187841</td>\n",
       "      <td>4.302191</td>\n",
       "      <td>3.987302</td>\n",
       "      <td>5.923300</td>\n",
       "      <td>8.318023</td>\n",
       "      <td>5.480140</td>\n",
       "      <td>6.849266</td>\n",
       "      <td>3.915834</td>\n",
       "      <td>4.580674</td>\n",
       "      <td>...</td>\n",
       "      <td>9.347400</td>\n",
       "      <td>4.448579</td>\n",
       "      <td>5.678010</td>\n",
       "      <td>4.647724</td>\n",
       "      <td>4.519629</td>\n",
       "      <td>5.084782</td>\n",
       "      <td>7.586717</td>\n",
       "      <td>4.147527</td>\n",
       "      <td>9.219702</td>\n",
       "      <td>4.389924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chek2</th>\n",
       "      <td>5.438097</td>\n",
       "      <td>8.147394</td>\n",
       "      <td>3.737049</td>\n",
       "      <td>3.643571</td>\n",
       "      <td>4.227227</td>\n",
       "      <td>6.925369</td>\n",
       "      <td>6.109890</td>\n",
       "      <td>4.225889</td>\n",
       "      <td>4.986666</td>\n",
       "      <td>4.894701</td>\n",
       "      <td>...</td>\n",
       "      <td>4.560132</td>\n",
       "      <td>4.798263</td>\n",
       "      <td>4.286907</td>\n",
       "      <td>5.410535</td>\n",
       "      <td>5.647682</td>\n",
       "      <td>6.589124</td>\n",
       "      <td>6.027516</td>\n",
       "      <td>9.764347</td>\n",
       "      <td>4.140214</td>\n",
       "      <td>4.399301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pink1</th>\n",
       "      <td>4.976832</td>\n",
       "      <td>3.663565</td>\n",
       "      <td>3.812837</td>\n",
       "      <td>3.417666</td>\n",
       "      <td>3.457396</td>\n",
       "      <td>2.932193</td>\n",
       "      <td>3.684580</td>\n",
       "      <td>4.098704</td>\n",
       "      <td>3.272404</td>\n",
       "      <td>3.470732</td>\n",
       "      <td>...</td>\n",
       "      <td>3.543564</td>\n",
       "      <td>3.284523</td>\n",
       "      <td>3.176308</td>\n",
       "      <td>3.464008</td>\n",
       "      <td>3.565589</td>\n",
       "      <td>4.394297</td>\n",
       "      <td>3.869984</td>\n",
       "      <td>4.303641</td>\n",
       "      <td>3.439632</td>\n",
       "      <td>3.187075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aff4</th>\n",
       "      <td>4.515953</td>\n",
       "      <td>4.675921</td>\n",
       "      <td>4.284176</td>\n",
       "      <td>5.815207</td>\n",
       "      <td>5.464257</td>\n",
       "      <td>4.550946</td>\n",
       "      <td>5.935291</td>\n",
       "      <td>4.221613</td>\n",
       "      <td>4.374451</td>\n",
       "      <td>4.090280</td>\n",
       "      <td>...</td>\n",
       "      <td>4.560803</td>\n",
       "      <td>4.376679</td>\n",
       "      <td>4.335781</td>\n",
       "      <td>4.284521</td>\n",
       "      <td>7.130577</td>\n",
       "      <td>5.304333</td>\n",
       "      <td>6.909337</td>\n",
       "      <td>5.435830</td>\n",
       "      <td>6.383567</td>\n",
       "      <td>6.796058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gencell_ep0_0  gencell_ep0_1  gencell_ep0_2  gencell_ep0_3  \\\n",
       "gene_name                                                               \n",
       "Rfc3            8.945637       5.733241       3.860522       5.619954   \n",
       "Cd47            3.738709       6.256884       4.448080       4.054791   \n",
       "Elmo2           5.200176       5.034015       4.367820       4.389033   \n",
       "Crip2           6.406047       6.777477       4.845940       5.980703   \n",
       "Pprc1           3.406488       4.168306       3.645792       4.300521   \n",
       "...                  ...            ...            ...            ...   \n",
       "Hprt            3.915553       3.186345       3.832254       2.772286   \n",
       "Atraid          5.856579       8.187841       4.302191       3.987302   \n",
       "Chek2           5.438097       8.147394       3.737049       3.643571   \n",
       "Pink1           4.976832       3.663565       3.812837       3.417666   \n",
       "Aff4            4.515953       4.675921       4.284176       5.815207   \n",
       "\n",
       "           gencell_ep0_4  gencell_ep0_5  gencell_ep0_6  gencell_ep0_7  \\\n",
       "gene_name                                                               \n",
       "Rfc3            5.586335       6.970235       4.338315       4.549016   \n",
       "Cd47            3.151270       5.373478       4.040785       3.867641   \n",
       "Elmo2           3.275808       4.553952       4.151926       4.272325   \n",
       "Crip2           6.169468       3.798367       5.310357       5.590196   \n",
       "Pprc1           4.956060       4.561098       4.906742       3.943385   \n",
       "...                  ...            ...            ...            ...   \n",
       "Hprt            2.920236       3.778947       3.616331       3.301115   \n",
       "Atraid          5.923300       8.318023       5.480140       6.849266   \n",
       "Chek2           4.227227       6.925369       6.109890       4.225889   \n",
       "Pink1           3.457396       2.932193       3.684580       4.098704   \n",
       "Aff4            5.464257       4.550946       5.935291       4.221613   \n",
       "\n",
       "           gencell_ep0_8  gencell_ep0_9  ...  gencell_ep0_490  \\\n",
       "gene_name                                ...                    \n",
       "Rfc3            5.009731       4.163322  ...         5.424246   \n",
       "Cd47            3.853901       3.849575  ...         4.048962   \n",
       "Elmo2           5.511501       5.136298  ...         6.041917   \n",
       "Crip2           5.810795       4.467186  ...         6.990990   \n",
       "Pprc1           5.413904       3.865657  ...         4.532197   \n",
       "...                  ...            ...  ...              ...   \n",
       "Hprt            3.704352       4.052122  ...         4.769273   \n",
       "Atraid          3.915834       4.580674  ...         9.347400   \n",
       "Chek2           4.986666       4.894701  ...         4.560132   \n",
       "Pink1           3.272404       3.470732  ...         3.543564   \n",
       "Aff4            4.374451       4.090280  ...         4.560803   \n",
       "\n",
       "           gencell_ep0_491  gencell_ep0_492  gencell_ep0_493  gencell_ep0_494  \\\n",
       "gene_name                                                                       \n",
       "Rfc3              4.402611         4.928729         4.162288         3.108255   \n",
       "Cd47              3.853764         3.765724         4.609506         3.302379   \n",
       "Elmo2             7.925032         4.330449         5.032185         6.416893   \n",
       "Crip2             5.949615         4.702023         6.335579         6.546120   \n",
       "Pprc1             5.760712         3.690476         4.809052         5.970742   \n",
       "...                    ...              ...              ...              ...   \n",
       "Hprt              4.114681         3.481516         4.099298         4.000013   \n",
       "Atraid            4.448579         5.678010         4.647724         4.519629   \n",
       "Chek2             4.798263         4.286907         5.410535         5.647682   \n",
       "Pink1             3.284523         3.176308         3.464008         3.565589   \n",
       "Aff4              4.376679         4.335781         4.284521         7.130577   \n",
       "\n",
       "           gencell_ep0_495  gencell_ep0_496  gencell_ep0_497  gencell_ep0_498  \\\n",
       "gene_name                                                                       \n",
       "Rfc3              3.963334         4.221949         5.123520         5.077371   \n",
       "Cd47              3.876153         4.352907         4.469342         3.901982   \n",
       "Elmo2             3.790214         4.398872         4.268808         6.591664   \n",
       "Crip2             4.798983         6.166876         5.177269         5.966042   \n",
       "Pprc1             6.596510         4.736276         4.186600         4.369345   \n",
       "...                    ...              ...              ...              ...   \n",
       "Hprt              3.558737         3.259285         3.562539         3.231498   \n",
       "Atraid            5.084782         7.586717         4.147527         9.219702   \n",
       "Chek2             6.589124         6.027516         9.764347         4.140214   \n",
       "Pink1             4.394297         3.869984         4.303641         3.439632   \n",
       "Aff4              5.304333         6.909337         5.435830         6.383567   \n",
       "\n",
       "           gencell_ep0_499  \n",
       "gene_name                   \n",
       "Rfc3              4.183359  \n",
       "Cd47              4.072795  \n",
       "Elmo2             6.079050  \n",
       "Crip2             4.368247  \n",
       "Pprc1             5.713038  \n",
       "...                    ...  \n",
       "Hprt              2.215208  \n",
       "Atraid            4.389924  \n",
       "Chek2             4.399301  \n",
       "Pink1             3.187075  \n",
       "Aff4              6.796058  \n",
       "\n",
       "[6807 rows x 500 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a single test set\n",
    "noise = gen_noise(EX_GEN_BATCH_SIZE)\n",
    "generated_profile = generator(noise, training=False)\n",
    "df_gen_prof_1 = data_frame_from_gen(generated_profile, 'gencell_ep0_')\n",
    "\n",
    "# Vis\n",
    "df_gen_prof_1\n",
    "\n",
    "# Save to file\n",
    "#df_gen_prof_1.to_csv(data_path + '/gen_prof_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GANN\n",
    "\n",
    "Define tensorboard metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_gen_loss = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n",
    "met_disc_loss = tf.keras.metrics.Mean('disc_loss', dtype=tf.float32)\n",
    "met_test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create log directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "gen_log_dir = 'logs/gradient_tape/' + current_time + '/gen_train'\n",
    "disc_log_dir = 'logs/gradient_tape/' + current_time + '/disc_train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/disc_test'\n",
    "all_log_dir = 'logs/gradient_tape/' + current_time + '/all'\n",
    "\n",
    "all_summary_writer = tf.summary.create_file_writer(all_log_dir)\n",
    "gen_summary_writer = tf.summary.create_file_writer(gen_log_dir)\n",
    "disc_summary_writer = tf.summary.create_file_writer(disc_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Epoch 1, Gen_loss: 0.2454620599746704, Disc_loss: 1.8153274059295654, Test_loss: 0.17771019041538239\n",
      "Epoch 2, Gen_loss: 0.2363108992576599, Disc_loss: 1.8622262477874756, Test_loss: 0.4955480098724365\n",
      "Epoch 3, Gen_loss: 0.34907957911491394, Disc_loss: 1.979713797569275, Test_loss: 0.9451809525489807\n",
      "Epoch 4, Gen_loss: 0.5352790355682373, Disc_loss: 1.7421742677688599, Test_loss: 0.7766973972320557\n",
      "Epoch 5, Gen_loss: 0.5957620143890381, Disc_loss: 1.5735509395599365, Test_loss: 0.6916200518608093\n",
      "Epoch 6, Gen_loss: 0.6484591364860535, Disc_loss: 1.3220919370651245, Test_loss: 0.4871649742126465\n",
      "Epoch 7, Gen_loss: 0.7735310792922974, Disc_loss: 1.0548357963562012, Test_loss: 0.3853340744972229\n",
      "Epoch 8, Gen_loss: 0.8803747296333313, Disc_loss: 0.9373819828033447, Test_loss: 0.41591861844062805\n",
      "Epoch 9, Gen_loss: 0.8895942568778992, Disc_loss: 1.067600131034851, Test_loss: 0.7159780859947205\n",
      "Epoch 10, Gen_loss: 0.9113759398460388, Disc_loss: 1.344366431236267, Test_loss: 0.8915939331054688\n",
      "Epoch 11, Gen_loss: 1.0102355480194092, Disc_loss: 1.297054648399353, Test_loss: 0.8419736623764038\n",
      "Epoch 12, Gen_loss: 1.049381136894226, Disc_loss: 1.3182075023651123, Test_loss: 0.8725400567054749\n",
      "Epoch 13, Gen_loss: 1.1647099256515503, Disc_loss: 1.1586917638778687, Test_loss: 0.700979471206665\n",
      "Epoch 14, Gen_loss: 1.0277934074401855, Disc_loss: 1.1976330280303955, Test_loss: 0.8324688076972961\n",
      "Epoch 15, Gen_loss: 0.9055386781692505, Disc_loss: 1.345924735069275, Test_loss: 0.786159336566925\n",
      "Epoch 16, Gen_loss: 0.8553834557533264, Disc_loss: 1.313254952430725, Test_loss: 0.751061201095581\n",
      "Epoch 17, Gen_loss: 0.9317775964736938, Disc_loss: 1.1989761590957642, Test_loss: 0.6503767967224121\n",
      "Epoch 18, Gen_loss: 0.9405387043952942, Disc_loss: 1.158071756362915, Test_loss: 0.6708391904830933\n",
      "Epoch 19, Gen_loss: 0.8207933902740479, Disc_loss: 1.272853970527649, Test_loss: 0.7132055759429932\n",
      "Epoch 20, Gen_loss: 0.7958155870437622, Disc_loss: 1.319398283958435, Test_loss: 0.6882097125053406\n",
      "Epoch 21, Gen_loss: 0.8692498207092285, Disc_loss: 1.235246181488037, Test_loss: 0.7042519450187683\n",
      "Epoch 22, Gen_loss: 0.8604457378387451, Disc_loss: 1.3304375410079956, Test_loss: 0.8079127073287964\n",
      "Epoch 23, Gen_loss: 0.8600638508796692, Disc_loss: 1.3528858423233032, Test_loss: 0.7792094945907593\n",
      "Epoch 24, Gen_loss: 0.7993091344833374, Disc_loss: 1.386353611946106, Test_loss: 0.7886988520622253\n",
      "Epoch 25, Gen_loss: 0.8274134397506714, Disc_loss: 1.3007088899612427, Test_loss: 0.655917227268219\n",
      "Epoch 26, Gen_loss: 0.8563207983970642, Disc_loss: 1.2264305353164673, Test_loss: 0.6997021436691284\n",
      "Epoch 27, Gen_loss: 0.7958552837371826, Disc_loss: 1.3084588050842285, Test_loss: 0.7373319864273071\n",
      "Epoch 28, Gen_loss: 0.7419417500495911, Disc_loss: 1.4580860137939453, Test_loss: 0.7914137840270996\n",
      "Epoch 29, Gen_loss: 0.7783869504928589, Disc_loss: 1.3857744932174683, Test_loss: 0.7634144425392151\n",
      "Epoch 30, Gen_loss: 0.7901211977005005, Disc_loss: 1.3595983982086182, Test_loss: 0.725084125995636\n"
     ]
    }
   ],
   "source": [
    "print('Running...')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Save checkpoints and gen example data\n",
    "    if epoch % 10 == 0:   \n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        # Generate a profile set\n",
    "        noise = gen_noise(EX_GEN_BATCH_SIZE)\n",
    "        generated_profile = generator(noise, training=False)\n",
    "        df_gen_prof = data_frame_from_gen(generated_profile, 'gencell_ep' + str(epoch) + '_')\n",
    "        df_gen_prof.to_csv(data_path + '/gen_prof_' + str(epoch) + '.csv')\n",
    "    \n",
    "    # Logging\n",
    "    start = time.time()\n",
    "    \n",
    "    #Train the epoch\n",
    "    for data_batch in train_dataset:\n",
    "        train_step(data_batch)\n",
    "        \n",
    "    #Run test data through discriminator\n",
    "    for data_batch in test_dataset:\n",
    "        test_decision = discriminator(data_batch, training=False)\n",
    "\n",
    "    test_loss = cross_entropy(tf.ones_like(test_decision), test_decision)\n",
    "    met_test_loss(test_loss)\n",
    "    \n",
    "    #Log metrics\n",
    "    with all_summary_writer.as_default():\n",
    "        tf.summary.scalar('2_gen_loss', met_gen_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('3_disc_loss', met_disc_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('3_test_loss', met_test_loss.result(), step=epoch)\n",
    "    \n",
    "    with gen_summary_writer.as_default():\n",
    "        tf.summary.scalar('1_loss', met_gen_loss.result(), step=epoch)\n",
    "           \n",
    "    with disc_summary_writer.as_default():\n",
    "        tf.summary.scalar('1_loss', met_disc_loss.result(), step=epoch)\n",
    "    \n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('1_loss', met_test_loss.result(), step=epoch)\n",
    "\n",
    "    # Logging\n",
    "    #print ('Time for epoch {} is {} sec.'.format(epoch + 1, time.time()-start))\n",
    "    time.time()\n",
    "      \n",
    "    #Log stats\n",
    "    template = 'Epoch {}, Gen_loss: {}, Disc_loss: {}, Test_loss: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                           met_gen_loss.result(), \n",
    "                           met_disc_loss.result(),\n",
    "                           met_test_loss.result()))\n",
    "    \n",
    "    # Reset metrics every epoch\n",
    "    met_gen_loss.reset_states()\n",
    "    met_disc_loss.reset_states()\n",
    "    met_test_loss.reset_states()\n",
    "    \n",
    "# Generate a profile set\n",
    "noise = gen_noise(EX_GEN_BATCH_SIZE)\n",
    "generated_profile = generator(noise, training=False)\n",
    "df_gen_prof = data_frame_from_gen(generated_profile, 'gencell_ep' + str(EPOCHS) + '_')\n",
    "df_gen_prof.to_csv(data_path + '/gen_prof_' + str(EPOCHS) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir {train_log_dir} --host localhost --port 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
